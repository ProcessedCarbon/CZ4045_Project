{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  9447\n",
      "Embedding Size:  100\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Model\n",
    "path = '../Pretrained_Models/'\n",
    "w2v_model = Word2Vec.load('../Pretrained_Models/TREC_pretrain.model')\n",
    "\n",
    "pretrained_weights = w2v_model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "\n",
    "print(\"Vocab Size: \", vocab_size)\n",
    "print(\"Embedding Size: \", embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Datasets/Processed/TREC'\n",
    "\n",
    "training_dev_df = pd.read_csv(f'{path}/train.dev.csv')\n",
    "training_df = pd.read_csv(f'{path}/train.csv')\n",
    "test_df = pd.read_csv(f'{path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "training_dev_df['label-coarse'] = label_encoder.fit_transform(training_dev_df['label-coarse'])\n",
    "test_df['label-coarse'] = label_encoder.fit_transform(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(training_dev_df['text'])\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(training_dev_df['text'])\n",
    "X_test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "sequence_length = 50  # Choose an appropriate sequence length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=sequence_length, padding='post')\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train = to_categorical(training_dev_df['label-coarse'])\n",
    "y_test = to_categorical(test_df['label-coarse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=sequence_length))\n",
    "model.add(LSTM(units=100))  # You can adjust the number of LSTM units\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:20:47.718461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2023-10-17 15:20:47.828734: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f865c00a0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-17 15:20:47.828768: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2023-10-17 15:20:47.833118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 15:20:47.902217: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 202ms/step - loss: 1.5793 - accuracy: 0.4111 - val_loss: 1.5723 - val_accuracy: 0.2800\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 1.4370 - accuracy: 0.4644 - val_loss: 1.7221 - val_accuracy: 0.2800\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 1.3607 - accuracy: 0.4644 - val_loss: 1.6137 - val_accuracy: 0.2800\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 1.3312 - accuracy: 0.4644 - val_loss: 1.6070 - val_accuracy: 0.2800\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.3121 - accuracy: 0.4644 - val_loss: 1.7423 - val_accuracy: 0.2800\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 114ms/step - loss: 1.3131 - accuracy: 0.4644 - val_loss: 1.7633 - val_accuracy: 0.2800\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.3081 - accuracy: 0.4644 - val_loss: 1.7152 - val_accuracy: 0.2800\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.3107 - accuracy: 0.4644 - val_loss: 1.6755 - val_accuracy: 0.2800\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 1.3095 - accuracy: 0.4644 - val_loss: 1.6938 - val_accuracy: 0.2800\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.3064 - accuracy: 0.4644 - val_loss: 1.7004 - val_accuracy: 0.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f87b8115d90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(X_train_padded, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 8ms/step - loss: 2.7935 - accuracy: 0.1622\n",
      "Test Loss: 2.793548583984375, Test Accuracy: 0.16223648190498352\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4045_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
